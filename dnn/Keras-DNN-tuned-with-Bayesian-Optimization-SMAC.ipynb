{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras deep neural network tuned with Bayesian optmization with SMAC\n",
    "\n",
    "This notebook aims to demonstrate on training and tuning deep neural networks using Bayesian optmization. The example problem used in the notebook is a binary classification problem. We use Keras (with Tensorflow backend) as a library to develop neural network models and SMAC for Bayesian optmization library. In particular, the notebook performs the following.\n",
    "* Create a sample binary-classification dataset that is imbalanced (ratio = 1:9)\n",
    "* Split the dataset into training, test, and validation set\n",
    "* Execute oversampling on the training set\n",
    "* Develop example a parameterized deep learning model based on Keras Sequential model\n",
    "* Focus on 5 parameters: learning rate, drop out rate, number of layers, number of hidden units, number of epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "%matplotlib inline  \n",
    "import keras\n",
    "import smac\n",
    "\n",
    "USE_RESAMPLING = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an example binary-classification dataset from Sklearn API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "x_raw, y_raw = make_classification( n_samples=50000,   n_features=70,\n",
    "                                    n_informative=10, n_redundant=60,\n",
    "                                    random_state=42, weights={0:1.8, 1:1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigate on how imbalanced it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([44789,  5211])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pd = pd.DataFrame(x_raw)\n",
    "Y_pd = pd.DataFrame(y_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into 2 parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_pd, Y_pd, test_size=0.20,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 70)\n",
      "(40000, 1)\n",
      "(10000, 70)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8912\n",
       "1    1088\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.iloc[:, 0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add oversampling here to only the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "\n",
    "if USE_RESAMPLING:\n",
    "    target_num_samples_major = Y_train[Y_train == 1].shape[0]\n",
    "    sampling_model = SMOTE()\n",
    "\n",
    "    X_resampled_train, Y_resampled_train = sampling_model.fit_sample(X_train, Y_train)\n",
    "    X_train = pd.DataFrame(X_resampled_train, columns=X_pd.columns)\n",
    "    Y_train = pd.DataFrame(Y_resampled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    35877\n",
       "0    35877\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.iloc[:,0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8912\n",
       "1    1088\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.iloc[:,0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(Y_train.values.reshape(-1, 1))\n",
    "Y_train_encoded = enc.transform(Y_train.values.reshape(-1, 1)).toarray()\n",
    "Y_test_encoded  = enc.transform(Y_test.values.reshape(-1, 1)).toarray()\n",
    "Y_train_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = X_train.shape[0]\n",
    "num_features = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, BatchNormalization\n",
    "from keras.optimizers import SGD, Adam\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_results(model, X, Y):\n",
    "    predict_probs = model.predict(X, batch_size=batch_size)\n",
    "    Y_prob_score = predict_probs[:,1]\n",
    "    \n",
    "    return roc_auc_score(Y, Y_prob_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrap the evaluation function entirely inside a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_architecture(learning_rate, num_layers, hidden_units, dropout_rate, num_epoch):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_units, activation='relu', input_dim=num_features))\n",
    "    \n",
    "    for _ in range(num_layers - 1):\n",
    "        model.add(Dense(hidden_units, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        model.add(BatchNormalization(axis=-1, momentum=0.99, \n",
    "                                     epsilon=0.001, center=True, scale=True, \n",
    "                                     beta_initializer='zeros', gamma_initializer='ones'))\n",
    "\n",
    "    # Add head at the end to be a softmax layer (Binary classification)\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    adam = Adam(lr=learning_rate)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=adam,\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parser to extract model parameters from configuration dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_from_cfg(cfg):\n",
    "    learning_rate = cfg[\"learning_rate\"]\n",
    "    dropout_rate  = cfg[\"dropout_rate\"]\n",
    "    num_layers    = cfg[\"num_layers\"]\n",
    "    hidden_units  = cfg[\"hidden_units\"]\n",
    "    num_epoch     = cfg[\"num_epoch\"]\n",
    "    \n",
    "    print(\"\"\" Learning rate = %.5f, num_layers = %s, hidden_units = %s, dropout_rate = %s, num_epoch = %s    \"\"\"\n",
    "          % ( learning_rate, num_layers, hidden_units, dropout_rate,  num_epoch)         \n",
    "         )\n",
    "    return model_architecture(learning_rate=learning_rate,\n",
    "                              num_layers=num_layers,\n",
    "                              hidden_units=hidden_units,\n",
    "                              dropout_rate=dropout_rate,\n",
    "                              num_epoch=num_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Wrap a full K-fold validation inside a single function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfold = 2\n",
    "def fit_dnn_from_cfg(cfg):\n",
    "    \"\"\" Evaluate DNN based on the configuration\n",
    "    Parameter: cfg dictionary \n",
    "    Returns:\n",
    "    --------\n",
    "    A cross validated score\n",
    "    \"\"\"\n",
    "    model = get_model_from_cfg(cfg)\n",
    "    num_epoch = cfg[\"num_epoch\"]\n",
    "    scores = np.zeros(nfold)\n",
    "    for n in range(nfold):\n",
    "        idx = np.array(range(X_train.shape[0]))\n",
    "        idx_valid = np.logical_and(idx>=X_train.shape[0]/nfold*n, idx<X_train.shape[0]/nfold*(n+1))\n",
    "        idx_train = np.logical_not(idx_valid)\n",
    "        model.fit(X_train.values[idx_train,:], Y_train_encoded[idx_train,:], \n",
    "                  epochs=num_epoch, batch_size=batch_size, shuffle=True,\n",
    "                  callbacks = None, verbose=1)\n",
    "        scores[n] = eval_results(model, X_train.values[idx_valid, :], Y_train_encoded[idx_valid, 1])\n",
    "    cross_val_auc = sum(scores)/nfold\n",
    "    print(\" Got cross validated score = %s, each fold score is %s\" % (cross_val_auc, str(scores)))\n",
    "    return 1 - cross_val_auc # We want to maximize cross-validated AUC (which is equivalent to minize 1 - fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import SMAC library and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smac\n",
    "\n",
    "# Import ConfigSpace and different types of parameters\n",
    "from smac.configspace import ConfigurationSpace\n",
    "from ConfigSpace.hyperparameters import CategoricalHyperparameter, \\\n",
    "    UniformFloatHyperparameter, UniformIntegerHyperparameter\n",
    "\n",
    "# Import SMAC-utilities\n",
    "from smac.tae.execute_func import ExecuteTAFuncDict\n",
    "from smac.scenario.scenario import Scenario\n",
    "from smac.facade.smac_facade import SMAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = ConfigurationSpace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[learning_rate, Type: UniformFloat, Range: [0.0001, 0.1], Default: 0.001,\n",
       " dropout_rate, Type: UniformFloat, Range: [0.001, 0.25], Default: 0.01,\n",
       " num_layers, Type: UniformInteger, Range: [5, 10], Default: 5,\n",
       " hidden_units, Type: UniformInteger, Range: [5, 30], Default: 10,\n",
       " num_epoch, Type: UniformInteger, Range: [2, 10], Default: 3]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = UniformFloatHyperparameter(\"learning_rate\", 1e-4, 1e-1, default=1e-3)\n",
    "dropout_rate  = UniformFloatHyperparameter(\"dropout_rate\",  0.001, 0.25, default=0.01)\n",
    "num_layers    = UniformIntegerHyperparameter(\"num_layers\",  5, 10, default=5)\n",
    "hidden_units  = UniformIntegerHyperparameter(\"hidden_units\",  5, 30, default=10)\n",
    "num_epoch     = UniformIntegerHyperparameter(\"num_epoch\",     2, 10, default=3)\n",
    "\n",
    "cs.add_hyperparameters([learning_rate, dropout_rate, num_layers, hidden_units, num_epoch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario object\n",
    "scenario = Scenario({\"run_obj\": \"quality\",   # we optimize quality (alternatively runtime)\n",
    "                     \"runcount-limit\": 5,  # maximum function evaluations\n",
    "                     \"cs\": cs,               # configuration space\n",
    "                     \"deterministic\": \"true\"\n",
    "                     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing! Depending on your machine, this might take a few minutes.\n",
      " Learning rate = 0.00100, num_layers = 5, hidden_units = 10, dropout_rate = 0.01, num_epoch = 3    \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 3s - loss: 0.2625 - acc: 0.8941     \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 3s - loss: 0.1461 - acc: 0.9382     \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 2s - loss: 0.1228 - acc: 0.9484     \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 2s - loss: 0.3279 - acc: 0.8991     \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 2s - loss: 0.0956 - acc: 0.9714     \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 2s - loss: 0.0853 - acc: 0.9766     \n",
      " Got cross validated score = 0.975832181194, each fold score is [ 0.97269983  0.97896453]\n",
      " Learning rate = 0.09412, num_layers = 8, hidden_units = 28, dropout_rate = 0.004292986996289652, num_epoch = 8    \n",
      "Epoch 1/8\n",
      "35877/35877 [==============================] - 5s - loss: 0.1784 - acc: 0.9242     \n",
      "Epoch 2/8\n",
      "35877/35877 [==============================] - 4s - loss: 0.1498 - acc: 0.9359     \n",
      "Epoch 3/8\n",
      "35877/35877 [==============================] - 5s - loss: 0.1380 - acc: 0.9404     \n",
      "Epoch 4/8\n",
      "35877/35877 [==============================] - 4s - loss: 0.1343 - acc: 0.9427     \n",
      "Epoch 5/8\n",
      "35877/35877 [==============================] - 4s - loss: 0.1420 - acc: 0.9431     \n",
      "Epoch 6/8\n",
      "35877/35877 [==============================] - 5s - loss: 0.1171 - acc: 0.9503     \n",
      "Epoch 7/8\n",
      "35877/35877 [==============================] - 5s - loss: 0.1290 - acc: 0.9484     \n",
      "Epoch 8/8\n",
      "35877/35877 [==============================] - 5s - loss: 0.1486 - acc: 0.9373     \n",
      "Epoch 1/8\n",
      "35877/35877 [==============================] - 4s - loss: 1.6544 - acc: 0.8958     \n",
      "Epoch 2/8\n",
      "35877/35877 [==============================] - 4s - loss: 1.6528 - acc: 0.8969     \n",
      "Epoch 3/8\n",
      "35877/35877 [==============================] - 5s - loss: 1.6528 - acc: 0.8969     \n",
      "Epoch 4/8\n",
      "35877/35877 [==============================] - 4s - loss: 1.6528 - acc: 0.8969     \n",
      "Epoch 5/8\n",
      "35877/35877 [==============================] - 4s - loss: 1.6528 - acc: 0.8969     \n",
      "Epoch 6/8\n",
      "35877/35877 [==============================] - 3s - loss: 1.6528 - acc: 0.8969     \n",
      "Epoch 7/8\n",
      "35877/35877 [==============================] - 4s - loss: 1.6528 - acc: 0.8969     \n",
      "Epoch 8/8\n",
      "35877/35877 [==============================] - 4s - loss: 1.6528 - acc: 0.8969     \n",
      " Got cross validated score = 0.522446041434, each fold score is [ 0.97354172  0.07135036]\n",
      " Learning rate = 0.06822, num_layers = 9, hidden_units = 12, dropout_rate = 0.12258252077655721, num_epoch = 9    \n",
      "Epoch 1/9\n",
      "35877/35877 [==============================] - 4s - loss: 0.2409 - acc: 0.9013     \n",
      "Epoch 2/9\n",
      "35877/35877 [==============================] - 4s - loss: 0.1715 - acc: 0.9203     \n",
      "Epoch 3/9\n",
      "35877/35877 [==============================] - 4s - loss: 0.1643 - acc: 0.9261     \n",
      "Epoch 4/9\n",
      "35877/35877 [==============================] - 5s - loss: 0.1634 - acc: 0.9273     \n",
      "Epoch 5/9\n",
      "35877/35877 [==============================] - 4s - loss: 0.1524 - acc: 0.9323     \n",
      "Epoch 6/9\n",
      "35877/35877 [==============================] - 5s - loss: 0.1466 - acc: 0.9360     \n",
      "Epoch 7/9\n",
      "35877/35877 [==============================] - 4s - loss: 0.1443 - acc: 0.9339     \n",
      "Epoch 8/9\n",
      "35877/35877 [==============================] - 4s - loss: 0.1417 - acc: 0.9371     \n",
      "Epoch 9/9\n",
      "35877/35877 [==============================] - 4s - loss: 0.1417 - acc: 0.9353     \n",
      "Epoch 1/9\n",
      "35877/35877 [==============================] - 4s - loss: 1.6569 - acc: 0.8949     \n",
      "Epoch 2/9\n",
      "35877/35877 [==============================] - 4s - loss: 1.6528 - acc: 0.8969     \n",
      "Epoch 3/9\n",
      "35877/35877 [==============================] - 5s - loss: 1.6528 - acc: 0.8969     \n",
      "Epoch 4/9\n",
      "35877/35877 [==============================] - 4s - loss: 1.6528 - acc: 0.8969     \n",
      "Epoch 5/9\n",
      "35877/35877 [==============================] - 4s - loss: 1.6528 - acc: 0.8969     \n",
      "Epoch 6/9\n",
      "35877/35877 [==============================] - 4s - loss: 1.6528 - acc: 0.8969     \n",
      "Epoch 7/9\n",
      "35877/35877 [==============================] - 5s - loss: 1.6528 - acc: 0.8969     \n",
      "Epoch 8/9\n",
      "35877/35877 [==============================] - 4s - loss: 1.6528 - acc: 0.8969     \n",
      "Epoch 9/9\n",
      "35877/35877 [==============================] - 4s - loss: 1.6528 - acc: 0.8969     \n",
      " Got cross validated score = 0.645162481235, each fold score is [ 0.97386224  0.31646272]\n",
      " Learning rate = 0.03591, num_layers = 8, hidden_units = 17, dropout_rate = 0.007277670988809294, num_epoch = 7    \n",
      "Epoch 1/7\n",
      "35877/35877 [==============================] - 4s - loss: 0.1624 - acc: 0.9294     \n",
      "Epoch 2/7\n",
      "35877/35877 [==============================] - 3s - loss: 0.1264 - acc: 0.9447     \n",
      "Epoch 3/7\n",
      "35877/35877 [==============================] - 3s - loss: 0.1200 - acc: 0.9486     \n",
      "Epoch 4/7\n",
      "35877/35877 [==============================] - 3s - loss: 0.1125 - acc: 0.9506     \n",
      "Epoch 5/7\n",
      "35877/35877 [==============================] - 4s - loss: 0.1084 - acc: 0.9528     \n",
      "Epoch 6/7\n",
      "35877/35877 [==============================] - 4s - loss: 0.1051 - acc: 0.9546     \n",
      "Epoch 7/7\n",
      "35877/35877 [==============================] - 4s - loss: 0.1076 - acc: 0.9534     \n",
      "Epoch 1/7\n",
      "35877/35877 [==============================] - 3s - loss: 0.1369 - acc: 0.9635     \n",
      "Epoch 2/7\n",
      "35877/35877 [==============================] - 4s - loss: 0.0871 - acc: 0.9776     \n",
      "Epoch 3/7\n",
      "35877/35877 [==============================] - 4s - loss: 0.0804 - acc: 0.9803     \n",
      "Epoch 4/7\n",
      "35877/35877 [==============================] - 4s - loss: 0.0747 - acc: 0.9823     \n",
      "Epoch 5/7\n",
      "35877/35877 [==============================] - 4s - loss: 0.0838 - acc: 0.9791     \n",
      "Epoch 6/7\n",
      "35877/35877 [==============================] - 5s - loss: 0.0947 - acc: 0.9755     \n",
      "Epoch 7/7\n",
      "35877/35877 [==============================] - 4s - loss: 0.0990 - acc: 0.9724     \n",
      " Got cross validated score = 0.977370476196, each fold score is [ 0.97444735  0.9802936 ]\n",
      " Learning rate = 0.03571, num_layers = 6, hidden_units = 28, dropout_rate = 0.09429145773928552, num_epoch = 4    \n",
      "Epoch 1/4\n",
      "35877/35877 [==============================] - 3s - loss: 0.1667 - acc: 0.9241     \n",
      "Epoch 2/4\n",
      "35877/35877 [==============================] - 3s - loss: 0.1296 - acc: 0.9426     \n",
      "Epoch 3/4\n",
      "35877/35877 [==============================] - 4s - loss: 0.1467 - acc: 0.9342     \n",
      "Epoch 4/4\n",
      "35877/35877 [==============================] - 3s - loss: 0.1205 - acc: 0.9473     \n",
      "Epoch 1/4\n",
      "35877/35877 [==============================] - 3s - loss: 0.1453 - acc: 0.9611     \n",
      "Epoch 2/4\n",
      "35877/35877 [==============================] - 3s - loss: 0.0904 - acc: 0.9780     \n",
      "Epoch 3/4\n",
      "35877/35877 [==============================] - 3s - loss: 0.0886 - acc: 0.9772     \n",
      "Epoch 4/4\n",
      "35877/35877 [==============================] - 3s - loss: 0.1047 - acc: 0.9726     \n",
      " Got cross validated score = 0.977515299082, each fold score is [ 0.97227212  0.98275848]\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimizing! Depending on your machine, this might take a few minutes.\")\n",
    "smac = SMAC(scenario=scenario, rng=np.random.RandomState(42),\n",
    "        tae_runner=fit_dnn_from_cfg)\n",
    "\n",
    "optimized_cfg = smac.optimize()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtained parameters during the search process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters was"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Configuration:\n",
       "  dropout_rate, Value: 0.09429145773928552\n",
       "  hidden_units, Value: 28\n",
       "  learning_rate, Value: 0.03570884778339389\n",
       "  num_epoch, Value: 4\n",
       "  num_layers, Value: 6"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best cost was (1 - AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Learning rate = 0.03571, num_layers = 6, hidden_units = 28, dropout_rate = 0.09429145773928552, num_epoch = 4    \n",
      "Epoch 1/4\n",
      "35877/35877 [==============================] - 3s - loss: 0.1890 - acc: 0.9139     \n",
      "Epoch 2/4\n",
      "35877/35877 [==============================] - 3s - loss: 0.1389 - acc: 0.9367     \n",
      "Epoch 3/4\n",
      "35877/35877 [==============================] - 3s - loss: 0.1286 - acc: 0.9425     \n",
      "Epoch 4/4\n",
      "35877/35877 [==============================] - 3s - loss: 0.1221 - acc: 0.9465     \n",
      "Epoch 1/4\n",
      "35877/35877 [==============================] - 2s - loss: 0.1452 - acc: 0.9579     \n",
      "Epoch 2/4\n",
      "35877/35877 [==============================] - 2s - loss: 0.0971 - acc: 0.9753     \n",
      "Epoch 3/4\n",
      "35877/35877 [==============================] - 2s - loss: 0.0955 - acc: 0.9743     \n",
      "Epoch 4/4\n",
      "35877/35877 [==============================] - 3s - loss: 0.0931 - acc: 0.9739     \n",
      " Got cross validated score = 0.977361616818, each fold score is [ 0.97288611  0.98183712]\n",
      "Optimized Value: 0.02\n"
     ]
    }
   ],
   "source": [
    "incumbent_value = fit_dnn_from_cfg(optimized_cfg)\n",
    "print(\"Optimized Value: %.2f\" % (incumbent_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the parameters on model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtained the searched parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Learning rate = 0.03571, num_layers = 6, hidden_units = 28, dropout_rate = 0.09429145773928552, num_epoch = 4    \n"
     ]
    }
   ],
   "source": [
    "model = get_model_from_cfg(optimized_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epoch = optimized_cfg[\"num_epoch\"]\n",
    "num_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trained the model for the whole training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "71754/71754 [==============================] - 7s - loss: 0.2105 - acc: 0.9320     \n",
      "Epoch 2/4\n",
      "71754/71754 [==============================] - 8s - loss: 0.1579 - acc: 0.9570     \n",
      "Epoch 3/4\n",
      "71754/71754 [==============================] - 6s - loss: 0.1546 - acc: 0.9583     \n",
      "Epoch 4/4\n",
      "71754/71754 [==============================] - 7s - loss: 0.1477 - acc: 0.9610     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa9c286c2b0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train.values, Y_train_encoded, \n",
    "                      epochs=num_epoch, batch_size=batch_size, shuffle=True,\n",
    "                      callbacks = None, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Test on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9818803773332716"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results(model, X_test.values, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
