# Character-level Seq2Seq model with attention
This repository contains implementation for a character-level seq2seq (with attention) model in Tensorflow. The code consists of an example notebook and supporting python files. This notebook demonstrates a working example of applying the character-level sequence-to-sequence with attention model to address a language correction problem. We limit the scope of the problem to fixing a single missing article (a, an, the). This means that given an input text with an article missing, the model would recommend a language-corrected text as an output.

In particular, the folder structure is the following.
* 
