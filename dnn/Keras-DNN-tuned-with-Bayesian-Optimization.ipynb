{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras deep neural network tuned with Bayesian optmization\n",
    "\n",
    "This notebook aims to demonstrate on training and tuning deep neural networks using Bayesian optmization. The example problem used in the notebook is a binary classification problem. We use Keras (with Tensorflow backend) as a library to develop neural network models and GPyOpt for Bayesian optmization library. In particular, the notebook performs the following.\n",
    "* Create a sample binary-classification dataset that is imbalanced (ratio = 1:9)\n",
    "* Split the dataset into training, test, and validation set\n",
    "* Execute oversampling on the training set\n",
    "* Develop example a parameterized deep learning model based on Keras Sequential model\n",
    "* Focus on 5 parameters: learning rate, drop out rate, number of layers, number of hidden units, number of epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "%matplotlib inline  \n",
    "import keras\n",
    "\n",
    "USE_RESAMPLING = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "x_raw, y_raw = make_classification( n_samples=50000,   n_features=70,\n",
    "                                    n_informative=10, n_redundant=60,\n",
    "                                    random_state=42, weights={0:1.8, 1:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([44789,  5211])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pd = pd.DataFrame(x_raw)\n",
    "Y_pd = pd.DataFrame(y_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_pd, Y_pd, test_size=0.20,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_valid, Y_test, Y_valid = train_test_split(X_test, Y_test, test_size=0.50, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 70)\n",
      "(5000, 1)\n",
      "(5000, 70)\n",
      "(5000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_valid.shape)\n",
    "print(Y_valid.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4468\n",
       "1     532\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.iloc[:, 0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add oversampling here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "\n",
    "if USE_RESAMPLING:\n",
    "    target_num_samples_major = Y_train[Y_train == 1].shape[0]\n",
    "    sampling_model = SMOTE()\n",
    "\n",
    "    X_resampled_train, Y_resampled_train = sampling_model.fit_sample(X_train, Y_train)\n",
    "    X_train = pd.DataFrame(X_resampled_train, columns=X_pd.columns)\n",
    "    Y_train = pd.DataFrame(Y_resampled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    35877\n",
       "0    35877\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.iloc[:,0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4468\n",
       "1     532\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.iloc[:,0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(Y_train.values.reshape(-1, 1))\n",
    "Y_train_encoded = enc.transform(Y_train.values.reshape(-1, 1)).toarray()\n",
    "Y_test_encoded  = enc.transform(Y_test.values.reshape(-1, 1)).toarray()\n",
    "Y_valid_encoded = enc.transform(Y_valid.values.reshape(-1, 1)).toarray()\n",
    "Y_train_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71754\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "num_samples = X_train.shape[0]\n",
    "print(num_samples)\n",
    "num_features = X_train.shape[1]\n",
    "print(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, BatchNormalization\n",
    "from keras.optimizers import SGD, Adam\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_results(model, X, Y):\n",
    "    predict_probs = model.predict(X, batch_size=batch_size)\n",
    "    Y_prob_score = predict_probs[:,1]\n",
    "    \n",
    "    return roc_auc_score(Y, Y_prob_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrap the evaluation function entirely inside a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_architecture(learning_rate, num_layers, hidden_units, dropout_rate, num_epoch):\n",
    "    model = Sequential()\n",
    "    for _ in range(num_layers):\n",
    "        model.add(Dense(hidden_units, activation='relu', input_dim=num_features))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        model.add(BatchNormalization(axis=-1, momentum=0.99, \n",
    "                                     epsilon=0.001, center=True, scale=True, \n",
    "                                     beta_initializer='zeros', gamma_initializer='ones'))\n",
    "\n",
    "    # Add head at the end to be a softmax layer (Binary classification)\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    adam = Adam(lr=learning_rate)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=adam,\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds   =  [  {'name': 'learning_rate',    'type': 'continuous',  'domain': (1e-4,1e-1) },\n",
    "               {'name': 'dropout_rate',     'type': 'continuous', 'domain':  (0.01, 0.25) },\n",
    "               {'name': 'num_layers',       'type': 'discrete',    'domain': (5,10)},\n",
    "               {'name': 'hidden_units',       'type': 'discrete',    'domain': (5,30)},\n",
    "               {'name': 'num_epoch',         'type': 'discrete',    'domain':  (2,3)}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_from_paras_row(paras_row, i):\n",
    "    learning_rate = paras_row[0]\n",
    "    dropout_rate  = paras_row[1]\n",
    "    num_layers    = int(paras_row[2])\n",
    "    hidden_units  = int(paras_row[3])\n",
    "    num_epoch     = paras_row[4]\n",
    "    \n",
    "    print(\"\"\" For row %s , learning rate = %.5f, num_layers = %s, hidden_units = %s, dropout_rate = %s, num_epoch = %s    \"\"\"\n",
    "          % (i, learning_rate, num_layers, hidden_units, dropout_rate,  num_epoch)         \n",
    "         )\n",
    "    return model_architecture(learning_rate=learning_rate,\n",
    "                              num_layers=num_layers,\n",
    "                              hidden_units=hidden_units,\n",
    "                              dropout_rate=dropout_rate,\n",
    "                              num_epoch=num_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfold = 2\n",
    "def fit_dnn(paras2d):\n",
    "    paras2d = np.atleast_2d(paras2d) # one row represents one set of parameters\n",
    "    \n",
    "    print(\" Getting in paras2d of shape = %s\" % str(paras2d.shape))\n",
    "    fs = np.zeros((paras2d.shape[0],1))\n",
    "    for i in range(paras2d.shape[0]):\n",
    "        fs[i] = 0 # accumulator for performance metric per fold\n",
    "        paras_row = paras2d[i]\n",
    "        model = get_model_from_paras_row(paras_row = paras_row, i=i)\n",
    "        \n",
    "        num_epoch = int(paras_row[4])        \n",
    "        for n in range(nfold):\n",
    "            idx = np.array(range(X_train.shape[0]))\n",
    "            idx_valid = np.logical_and(idx>=X_train.shape[0]/nfold*n, idx<X_train.shape[0]/nfold*(n+1))\n",
    "            idx_train = np.logical_not(idx_valid)\n",
    "            model.fit(X_train.values[idx_train,:], Y_train_encoded[idx_train,:], \n",
    "                      epochs=num_epoch, batch_size=batch_size, shuffle=True,\n",
    "                      callbacks = None, verbose=1)\n",
    "            fs[i] += eval_results(model, X_train.values[idx_valid, :], Y_train_encoded[idx_valid, 1])\n",
    "        fs[i] *= 1./nfold\n",
    "        \n",
    "        print(\" For row %s : we get the average cross validation score of %.3f: model paras = %s \" % (i, fs[i], paras_row))\n",
    "    return 1 - fs # We want to maximize fs (which is equivalent to minize 1 - fs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPyOpt # Bayesian optimization library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Getting in paras2d of shape = (1, 5)\n",
      " For row 0 , learning rate = 0.00877, num_layers = 5, hidden_units = 5, dropout_rate = 0.063994714318, num_epoch = 2.0    \n",
      "Epoch 1/2\n",
      "35877/35877 [==============================] - 7s - loss: 0.2243 - acc: 0.9089     \n",
      "Epoch 2/2\n",
      "35877/35877 [==============================] - 4s - loss: 0.1826 - acc: 0.9221     \n",
      "Epoch 1/2\n",
      "35877/35877 [==============================] - 4s - loss: 0.2152 - acc: 0.9196     \n",
      "Epoch 2/2\n",
      "35877/35877 [==============================] - 5s - loss: 0.1615 - acc: 0.9414     \n",
      " For row 0 : we get the average cross validation score of 0.971: model paras = [ 0.00876781  0.06399471  5.          5.          2.        ] \n",
      " Getting in paras2d of shape = (1, 5)\n",
      " For row 0 , learning rate = 0.03813, num_layers = 10, hidden_units = 5, dropout_rate = 0.204671785028, num_epoch = 3.0    \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 9s - loss: 0.3357 - acc: 0.8955     \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 7s - loss: 0.3308 - acc: 0.8969     \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 6s - loss: 0.3232 - acc: 0.8965     \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 8s - loss: 0.3168 - acc: 0.8918     \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 7s - loss: 0.3022 - acc: 0.8971     \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 8s - loss: 0.2909 - acc: 0.8949     \n",
      " For row 0 : we get the average cross validation score of 0.916: model paras = [  0.03812852   0.20467179  10.           5.           3.        ] \n",
      " Getting in paras2d of shape = (1, 5)\n",
      " For row 0 , learning rate = 0.02691, num_layers = 10, hidden_units = 30, dropout_rate = 0.159387198323, num_epoch = 3.0    \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 12s - loss: 0.2334 - acc: 0.9012    \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 8s - loss: 0.1800 - acc: 0.9175     \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 8s - loss: 0.1657 - acc: 0.9231     \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 8s - loss: 0.1919 - acc: 0.9275     \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 8s - loss: 0.1494 - acc: 0.9442     \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 8s - loss: 0.1431 - acc: 0.9486     \n",
      " For row 0 : we get the average cross validation score of 0.975: model paras = [  2.69126347e-02   1.59387198e-01   1.00000000e+01   3.00000000e+01\n",
      "   3.00000000e+00] \n",
      " Getting in paras2d of shape = (1, 5)\n",
      " For row 0 , learning rate = 0.00160, num_layers = 5, hidden_units = 30, dropout_rate = 0.0183572137312, num_epoch = 3.0    \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 7s - loss: 0.1881 - acc: 0.9242     \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 5s - loss: 0.1150 - acc: 0.9515     \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 5s - loss: 0.1032 - acc: 0.9552     \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 5s - loss: 0.1743 - acc: 0.9511     \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 5s - loss: 0.0751 - acc: 0.9789     \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 5s - loss: 0.0685 - acc: 0.9820     \n",
      " For row 0 : we get the average cross validation score of 0.980: model paras = [  1.59671076e-03   1.83572137e-02   5.00000000e+00   3.00000000e+01\n",
      "   3.00000000e+00] \n",
      " Getting in paras2d of shape = (1, 5)\n",
      " For row 0 , learning rate = 0.00969, num_layers = 10, hidden_units = 5, dropout_rate = 0.198426031097, num_epoch = 2.0    \n",
      "Epoch 1/2\n",
      "35877/35877 [==============================] - 9s - loss: 0.3430 - acc: 0.8932     \n",
      "Epoch 2/2\n",
      "35877/35877 [==============================] - 8s - loss: 0.3283 - acc: 0.8969     \n",
      "Epoch 1/2\n",
      "35877/35877 [==============================] - 8s - loss: 0.3289 - acc: 0.8864     \n",
      "Epoch 2/2\n",
      "35877/35877 [==============================] - 10s - loss: 0.3143 - acc: 0.8969    \n",
      " For row 0 : we get the average cross validation score of 0.868: model paras = [  9.68984695e-03   1.98426031e-01   1.00000000e+01   5.00000000e+00\n",
      "   2.00000000e+00] \n",
      "The set cost function is ignored! LBC acquisition does not make sense with cost.\n"
     ]
    }
   ],
   "source": [
    "opt = GPyOpt.methods.BayesianOptimization(f = fit_dnn,          # function to optimize       \n",
    "                                          domain = bounds,          # box-constrains of the problem\n",
    "                                          acquisition_type ='LCB',  # LCB acquisition\n",
    "                                          acquisition_weight = 0.1) # Exploration exploitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Getting in paras2d of shape = (1, 5)\n",
      " For row 0 , learning rate = 0.00869, num_layers = 5, hidden_units = 30, dropout_rate = 0.086949033055, num_epoch = 3.0    \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 8s - loss: 0.1735 - acc: 0.9233     \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 5s - loss: 0.1282 - acc: 0.9438     \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 5s - loss: 0.1210 - acc: 0.9495     \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 6s - loss: 0.1409 - acc: 0.9529     \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 6s - loss: 0.1031 - acc: 0.9683     \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 6s - loss: 0.0894 - acc: 0.9751     \n",
      " For row 0 : we get the average cross validation score of 0.978: model paras = [  8.69498378e-03   8.69490331e-02   5.00000000e+00   3.00000000e+01\n",
      "   3.00000000e+00] \n",
      " Getting in paras2d of shape = (1, 5)\n",
      " For row 0 , learning rate = 0.02889, num_layers = 5, hidden_units = 30, dropout_rate = 0.01, num_epoch = 3.0    \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 7s - loss: 0.1590 - acc: 0.9291     \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 6s - loss: 0.1317 - acc: 0.9427     \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 6s - loss: 0.1180 - acc: 0.9496     \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 6s - loss: 0.1217 - acc: 0.9643     \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 5s - loss: 0.0843 - acc: 0.9752     \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 6s - loss: 0.0752 - acc: 0.9786     \n",
      " For row 0 : we get the average cross validation score of 0.979: model paras = [  2.88949648e-02   1.00000000e-02   5.00000000e+00   3.00000000e+01\n",
      "   3.00000000e+00] \n",
      " Getting in paras2d of shape = (1, 5)\n",
      " For row 0 , learning rate = 0.00010, num_layers = 5, hidden_units = 30, dropout_rate = 0.01, num_epoch = 3.0    \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 7s - loss: 0.5593 - acc: 0.7479     \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 5s - loss: 0.3011 - acc: 0.9083     \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 6s - loss: 0.2100 - acc: 0.9268     \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 5s - loss: 1.0454 - acc: 0.4745     \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 5s - loss: 0.4578 - acc: 0.9078     \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 5s - loss: 0.2634 - acc: 0.9512     \n",
      " For row 0 : we get the average cross validation score of 0.960: model paras = [  1.00000000e-04   1.00000000e-02   5.00000000e+00   3.00000000e+01\n",
      "   3.00000000e+00] \n",
      " Getting in paras2d of shape = (1, 5)\n",
      " For row 0 , learning rate = 0.10000, num_layers = 5, hidden_units = 30, dropout_rate = 0.25, num_epoch = 3.0    \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 8s - loss: 0.2583 - acc: 0.8957     \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 5s - loss: 0.2321 - acc: 0.9047     \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 5s - loss: 0.2243 - acc: 0.9037     \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 6s - loss: 1.6533 - acc: 0.8951     \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 5s - loss: 1.6528 - acc: 0.8969     \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 5s - loss: 1.6528 - acc: 0.8969     \n",
      " For row 0 : we get the average cross validation score of 0.685: model paras = [  0.1    0.25   5.    30.     3.  ] \n",
      " Getting in paras2d of shape = (1, 5)\n",
      " For row 0 , learning rate = 0.01821, num_layers = 5, hidden_units = 30, dropout_rate = 0.0468784451517, num_epoch = 3.0    \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 8s - loss: 0.1717 - acc: 0.9237     \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 5s - loss: 0.1330 - acc: 0.9424     \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 6s - loss: 0.1198 - acc: 0.9487     \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 5s - loss: 0.1281 - acc: 0.9630     \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 5s - loss: 0.0893 - acc: 0.9739     \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 5s - loss: 0.0818 - acc: 0.9768     \n",
      " For row 0 : we get the average cross validation score of 0.979: model paras = [  1.82075554e-02   4.68784452e-02   5.00000000e+00   3.00000000e+01\n",
      "   3.00000000e+00] \n",
      " Getting in paras2d of shape = (1, 5)\n",
      " For row 0 , learning rate = 0.00010, num_layers = 5, hidden_units = 30, dropout_rate = 0.0624843738398, num_epoch = 3.0    \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 8s - loss: 0.6016 - acc: 0.7151     \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 5s - loss: 0.3397 - acc: 0.8793     \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 5s - loss: 0.2570 - acc: 0.9064     \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 7s - loss: 1.0543 - acc: 0.4710     \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 7s - loss: 0.4321 - acc: 0.8956     \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 6s - loss: 0.2638 - acc: 0.9358     \n",
      " For row 0 : we get the average cross validation score of 0.952: model paras = [  1.00000000e-04   6.24843738e-02   5.00000000e+00   3.00000000e+01\n",
      "   3.00000000e+00] \n",
      " Getting in paras2d of shape = (1, 5)\n",
      " For row 0 , learning rate = 0.04473, num_layers = 5, hidden_units = 30, dropout_rate = 0.0353736309225, num_epoch = 3.0    \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 9s - loss: 0.1713 - acc: 0.9265     \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 6s - loss: 0.1430 - acc: 0.9375     \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 6s - loss: 0.1359 - acc: 0.9420     \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 6s - loss: 0.1453 - acc: 0.9582     \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 7s - loss: 0.1084 - acc: 0.9668     \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 6s - loss: 0.0997 - acc: 0.9702     \n",
      " For row 0 : we get the average cross validation score of 0.978: model paras = [  0.04472927   0.03537363   5.          30.           3.        ] \n",
      " Getting in paras2d of shape = (1, 5)\n",
      " For row 0 , learning rate = 0.03320, num_layers = 5, hidden_units = 30, dropout_rate = 0.0277778779778, num_epoch = 3.0    \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 10s - loss: 0.1681 - acc: 0.9239    \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 5s - loss: 0.1381 - acc: 0.9383     \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 6s - loss: 0.1327 - acc: 0.9437     \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 6s - loss: 0.1381 - acc: 0.9570     \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 7s - loss: 0.1157 - acc: 0.9630     \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 6s - loss: 0.0907 - acc: 0.9736     \n",
      " For row 0 : we get the average cross validation score of 0.977: model paras = [  3.31966903e-02   2.77778780e-02   5.00000000e+00   3.00000000e+01\n",
      "   3.00000000e+00] \n",
      " Getting in paras2d of shape = (1, 5)\n",
      " For row 0 , learning rate = 0.03149, num_layers = 5, hidden_units = 30, dropout_rate = 0.035320476315, num_epoch = 3.0    \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 8s - loss: 0.1725 - acc: 0.9254     \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 6s - loss: 0.1360 - acc: 0.9393     \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 6s - loss: 0.1292 - acc: 0.9443     \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 5s - loss: 0.1442 - acc: 0.9562     \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 7s - loss: 0.0942 - acc: 0.9725     \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 7s - loss: 0.0831 - acc: 0.9762     \n",
      " For row 0 : we get the average cross validation score of 0.976: model paras = [  0.03148783   0.03532048   5.          30.           3.        ] \n",
      " Getting in paras2d of shape = (1, 5)\n",
      " For row 0 , learning rate = 0.03519, num_layers = 5, hidden_units = 30, dropout_rate = 0.0685678580304, num_epoch = 3.0    \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 10s - loss: 0.1787 - acc: 0.9202    \n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35877/35877 [==============================] - 7s - loss: 0.1465 - acc: 0.9325     \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 6s - loss: 0.1328 - acc: 0.9418     \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 7s - loss: 0.1550 - acc: 0.9498     \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 7s - loss: 0.1284 - acc: 0.9576     \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 7s - loss: 0.1354 - acc: 0.9546     \n",
      " For row 0 : we get the average cross validation score of 0.976: model paras = [  0.03519408   0.06856786   5.          30.           3.        ] \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmIAAAFRCAYAAADXUMF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe3471e0f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "opt.run_optimization(max_iter=10)\n",
    "opt.plot_convergence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtained parameters during the search process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameter was"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.59671076e-03,   1.83572137e-02,   5.00000000e+00,\n",
       "         3.00000000e+01,   3.00000000e+00])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.x_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best cost was (1 - AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02002737])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.fx_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the parameters on model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtained the searched parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " For row 0 , learning rate = 0.00160, num_layers = 5, hidden_units = 30, dropout_rate = 0.0183572137312, num_epoch = 3.0    \n"
     ]
    }
   ],
   "source": [
    "model = get_model_from_paras_row(opt.x_opt, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epoch = int(opt.x_opt[4])\n",
    "num_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trained the model for the whole training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "71754/71754 [==============================] - 16s - loss: 0.1835 - acc: 0.9384    \n",
      "Epoch 2/3\n",
      "71754/71754 [==============================] - 12s - loss: 0.1371 - acc: 0.9591    \n",
      "Epoch 3/3\n",
      "71754/71754 [==============================] - 14s - loss: 0.1262 - acc: 0.9638    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe32df4f278>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train.values, Y_train_encoded, \n",
    "                      epochs=num_epoch, batch_size=batch_size, shuffle=True,\n",
    "                      callbacks = None, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Test on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97437647666615057"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results(model, X_test.values, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
