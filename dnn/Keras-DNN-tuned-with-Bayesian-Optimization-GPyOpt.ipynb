{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras deep neural network tuned with Bayesian optmization\n",
    "\n",
    "This notebook aims to demonstrate on training and tuning deep neural networks using Bayesian optmization. The example problem used in the notebook is a binary classification problem. We use Keras (with Tensorflow backend) as a library to develop neural network models and GPyOpt for Bayesian optmization library. In particular, the notebook performs the following.\n",
    "* Create a sample binary-classification dataset that is imbalanced (ratio = 1:9)\n",
    "* Split the dataset into training, test, and validation set\n",
    "* Execute oversampling on the training set\n",
    "* Develop example a parameterized deep learning model based on Keras Sequential model\n",
    "* Focus on 5 parameters: learning rate, drop out rate, number of layers, number of hidden units, number of epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "%matplotlib inline  \n",
    "import keras\n",
    "\n",
    "USE_RESAMPLING = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an example binary-classification dataset from Sklearn API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "x_raw, y_raw = make_classification( n_samples=50000,   n_features=70,\n",
    "                                    n_informative=10, n_redundant=60,\n",
    "                                    random_state=42, weights={0:1.8, 1:1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigate on how imbalanced it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([44789,  5211])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pd = pd.DataFrame(x_raw)\n",
    "Y_pd = pd.DataFrame(y_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into 2 parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_pd, Y_pd, test_size=0.20,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 70)\n",
      "(40000, 1)\n",
      "(10000, 70)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8912\n",
       "1    1088\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.iloc[:, 0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add oversampling here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "\n",
    "if USE_RESAMPLING:\n",
    "    target_num_samples_major = Y_train[Y_train == 1].shape[0]\n",
    "    sampling_model = SMOTE()\n",
    "\n",
    "    X_resampled_train, Y_resampled_train = sampling_model.fit_sample(X_train, Y_train)\n",
    "    X_train = pd.DataFrame(X_resampled_train, columns=X_pd.columns)\n",
    "    Y_train = pd.DataFrame(Y_resampled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    35877\n",
       "0    35877\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.iloc[:,0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8912\n",
       "1    1088\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.iloc[:,0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(Y_train.values.reshape(-1, 1))\n",
    "Y_train_encoded = enc.transform(Y_train.values.reshape(-1, 1)).toarray()\n",
    "Y_test_encoded  = enc.transform(Y_test.values.reshape(-1, 1)).toarray()\n",
    "Y_train_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = X_train.shape[0]\n",
    "num_features = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, BatchNormalization\n",
    "from keras.optimizers import SGD, Adam\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_results(model, X, Y):\n",
    "    predict_probs = model.predict(X, batch_size=batch_size)\n",
    "    Y_prob_score = predict_probs[:,1]\n",
    "    \n",
    "    return roc_auc_score(Y, Y_prob_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrap the evaluation function entirely inside a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_architecture(learning_rate, num_layers, hidden_units, dropout_rate, num_epoch):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_units, activation='relu', input_dim=num_features))\n",
    "    \n",
    "    for _ in range(num_layers - 1):\n",
    "        model.add(Dense(hidden_units, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        model.add(BatchNormalization(axis=-1, momentum=0.99, \n",
    "                                     epsilon=0.001, center=True, scale=True, \n",
    "                                     beta_initializer='zeros', gamma_initializer='ones'))\n",
    "\n",
    "    # Add head at the end to be a softmax layer (Binary classification)\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    adam = Adam(lr=learning_rate)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=adam,\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds   =  [  {'name': 'learning_rate',    'type': 'continuous',  'domain': (1e-4,1e-1) }, # Min, max for each parameter\n",
    "               {'name': 'dropout_rate',     'type': 'continuous',  'domain':  (0.01, 0.25) },\n",
    "               {'name': 'num_layers',       'type': 'discrete',    'domain': (5,10)},\n",
    "               {'name': 'hidden_units',     'type': 'discrete',    'domain': (5,30)},\n",
    "               {'name': 'num_epoch',        'type': 'discrete',    'domain':  (2,3)}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_from_paras_row(paras_row, i):\n",
    "    learning_rate = paras_row[0]\n",
    "    dropout_rate  = paras_row[1]\n",
    "    num_layers    = int(paras_row[2]) \n",
    "    hidden_units  = int(paras_row[3])\n",
    "    num_epoch     = paras_row[4]\n",
    "    \n",
    "    print(\"\"\" For row %s , learning rate = %.5f, num_layers = %s, hidden_units = %s, dropout_rate = %s, num_epoch = %s    \"\"\"\n",
    "          % (i, learning_rate, num_layers, hidden_units, dropout_rate,  num_epoch)         \n",
    "         )\n",
    "    return model_architecture(learning_rate=learning_rate,\n",
    "                              num_layers=num_layers,\n",
    "                              hidden_units=hidden_units,\n",
    "                              dropout_rate=dropout_rate,\n",
    "                              num_epoch=num_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Wrap a full K-fold validation inside a single function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfold = 2\n",
    "def fit_dnn(paras2d):\n",
    "    paras2d = np.atleast_2d(paras2d) # one row represents one set of parameters\n",
    "    \n",
    "    print(\" Getting in paras2d of shape = %s\" % str(paras2d.shape))\n",
    "    fs = np.zeros((paras2d.shape[0],1))\n",
    "    for i in range(paras2d.shape[0]):\n",
    "        fs[i] = 0 # accumulator for performance metric per fold\n",
    "        paras_row = paras2d[i]\n",
    "        model = get_model_from_paras_row(paras_row = paras_row, i=i)\n",
    "        \n",
    "        num_epoch = int(paras_row[4])        \n",
    "        for n in range(nfold):\n",
    "            idx = np.array(range(X_train.shape[0]))\n",
    "            idx_valid = np.logical_and(idx>=X_train.shape[0]/nfold*n, idx<X_train.shape[0]/nfold*(n+1))\n",
    "            idx_train = np.logical_not(idx_valid)\n",
    "            model.fit(X_train.values[idx_train,:], Y_train_encoded[idx_train,:], \n",
    "                      epochs=num_epoch, batch_size=batch_size, shuffle=True,\n",
    "                      callbacks = None, verbose=1)\n",
    "            fs[i] += eval_results(model, X_train.values[idx_valid, :], Y_train_encoded[idx_valid, 1])\n",
    "        fs[i] *= 1./nfold\n",
    "        \n",
    "        print(\" For row %s : we get the average cross validation score of %.3f: model paras = %s \" % (i, fs[i], paras_row))\n",
    "    return 1 - fs # We want to maximize fs (which is equivalent to minize 1 - fs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPyOpt # Bayesian optimization library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Getting in paras2d of shape = (1, 5)\n",
      " For row 0 , learning rate = 0.02780, num_layers = 10, hidden_units = 30, dropout_rate = 0.113639664222, num_epoch = 2.0    \n",
      "Epoch 1/2\n",
      "35877/35877 [==============================] - 16s - loss: 0.2066 - acc: 0.9085    \n",
      "Epoch 2/2\n",
      "35877/35877 [==============================] - 9s - loss: 0.1535 - acc: 0.9296     \n",
      "Epoch 1/2\n",
      "35877/35877 [==============================] - 9s - loss: 0.1562 - acc: 0.9486     \n",
      "Epoch 2/2\n",
      "35877/35877 [==============================] - 10s - loss: 0.1267 - acc: 0.9583    \n",
      " For row 0 : we get the average cross validation score of 0.973: model paras = [  2.77999055e-02   1.13639664e-01   1.00000000e+01   3.00000000e+01\n",
      "   2.00000000e+00] \n",
      " Getting in paras2d of shape = (1, 5)\n",
      " For row 0 , learning rate = 0.06645, num_layers = 5, hidden_units = 5, dropout_rate = 0.154261957554, num_epoch = 2.0    \n",
      "Epoch 1/2\n",
      "35877/35877 [==============================] - 9s - loss: 0.2602 - acc: 0.8949     \n",
      "Epoch 2/2\n",
      "35877/35877 [==============================] - 7s - loss: 0.2335 - acc: 0.8998     \n",
      "Epoch 1/2\n",
      "35877/35877 [==============================] - 6s - loss: 0.2341 - acc: 0.9254     \n",
      "Epoch 2/2\n",
      "35877/35877 [==============================] - 6s - loss: 0.1868 - acc: 0.9414     \n",
      " For row 0 : we get the average cross validation score of 0.958: model paras = [ 0.06645326  0.15426196  5.          5.          2.        ] \n",
      " Getting in paras2d of shape = (1, 5)\n",
      " For row 0 , learning rate = 0.04501, num_layers = 10, hidden_units = 30, dropout_rate = 0.104637769081, num_epoch = 3.0    \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 13s - loss: 0.2060 - acc: 0.9111    \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 11s - loss: 0.1630 - acc: 0.9244    \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 13s - loss: 0.1444 - acc: 0.9332    \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 11s - loss: 0.2432 - acc: 0.9282    \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 10s - loss: 0.1834 - acc: 0.9350    \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 9s - loss: 0.1547 - acc: 0.9450     \n",
      " For row 0 : we get the average cross validation score of 0.976: model paras = [  0.04500794   0.10463777  10.          30.           3.        ] \n",
      " Getting in paras2d of shape = (1, 5)\n",
      " For row 0 , learning rate = 0.05788, num_layers = 5, hidden_units = 5, dropout_rate = 0.197433297327, num_epoch = 3.0    \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 8s - loss: 0.2356 - acc: 0.9056     \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 5s - loss: 0.1972 - acc: 0.9153     \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 5s - loss: 0.1972 - acc: 0.9149     \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 5s - loss: 0.2094 - acc: 0.9283     \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 5s - loss: 0.1811 - acc: 0.9340     \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 6s - loss: 0.1778 - acc: 0.9385     \n",
      " For row 0 : we get the average cross validation score of 0.969: model paras = [ 0.05787665  0.1974333   5.          5.          3.        ] \n",
      " Getting in paras2d of shape = (1, 5)\n",
      " For row 0 , learning rate = 0.01875, num_layers = 10, hidden_units = 30, dropout_rate = 0.0999013010231, num_epoch = 2.0    \n",
      "Epoch 1/2\n",
      "35877/35877 [==============================] - 13s - loss: 0.1854 - acc: 0.9182    \n",
      "Epoch 2/2\n",
      "35877/35877 [==============================] - 9s - loss: 0.1408 - acc: 0.9350     \n",
      "Epoch 1/2\n",
      "35877/35877 [==============================] - 9s - loss: 0.1860 - acc: 0.9340     \n",
      "Epoch 2/2\n",
      "35877/35877 [==============================] - 10s - loss: 0.1294 - acc: 0.9553    \n",
      " For row 0 : we get the average cross validation score of 0.975: model paras = [  1.87486200e-02   9.99013010e-02   1.00000000e+01   3.00000000e+01\n",
      "   2.00000000e+00] \n",
      "The set cost function is ignored! LBC acquisition does not make sense with cost.\n"
     ]
    }
   ],
   "source": [
    "opt = GPyOpt.methods.BayesianOptimization(f = fit_dnn,          # function to optimize       \n",
    "                                          domain = bounds,          # box-constrains of the problem\n",
    "                                          acquisition_type ='LCB',  # LCB acquisition\n",
    "                                          acquisition_weight = 0.1) # Exploration exploitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Getting in paras2d of shape = (1, 5)\n",
      " For row 0 , learning rate = 0.03469, num_layers = 10, hidden_units = 30, dropout_rate = 0.0925195191195, num_epoch = 3.0    \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 12s - loss: 0.1922 - acc: 0.9143    \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 9s - loss: 0.1537 - acc: 0.9304     \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 10s - loss: 0.1426 - acc: 0.9337    \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 9s - loss: 0.1984 - acc: 0.9340     \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 9s - loss: 0.1431 - acc: 0.9508     \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 9s - loss: 0.1328 - acc: 0.9540     \n",
      " For row 0 : we get the average cross validation score of 0.975: model paras = [  0.03469015   0.09251952  10.          30.           3.        ] \n",
      " Getting in paras2d of shape = (1, 5)\n",
      " For row 0 , learning rate = 0.06172, num_layers = 10, hidden_units = 30, dropout_rate = 0.11066094587, num_epoch = 3.0    \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 12s - loss: 0.2168 - acc: 0.9041    \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 10s - loss: 0.1707 - acc: 0.9219    \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 10s - loss: 0.1535 - acc: 0.9334    \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 8s - loss: 0.1837 - acc: 0.9400     \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 9s - loss: 0.1364 - acc: 0.9571     \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 9s - loss: 0.1632 - acc: 0.9451     \n",
      " For row 0 : we get the average cross validation score of 0.975: model paras = [  0.06172422   0.11066095  10.          30.           3.        ] \n",
      " Getting in paras2d of shape = (1, 5)\n",
      " For row 0 , learning rate = 0.00010, num_layers = 10, hidden_units = 30, dropout_rate = 0.01, num_epoch = 3.0    \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 13s - loss: 0.5759 - acc: 0.7113    \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 11s - loss: 0.3284 - acc: 0.8880    \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 11s - loss: 0.2492 - acc: 0.9065    \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 10s - loss: 1.0565 - acc: 0.4764    \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 10s - loss: 0.4779 - acc: 0.9099    \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 9s - loss: 0.3054 - acc: 0.9375     \n",
      " For row 0 : we get the average cross validation score of 0.920: model paras = [  1.00000000e-04   1.00000000e-02   1.00000000e+01   3.00000000e+01\n",
      "   3.00000000e+00] \n",
      " Getting in paras2d of shape = (1, 5)\n",
      " For row 0 , learning rate = 0.03164, num_layers = 10, hidden_units = 30, dropout_rate = 0.108027100964, num_epoch = 3.0    \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 14s - loss: 0.1973 - acc: 0.9140    \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 9s - loss: 0.1506 - acc: 0.9316     \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 10s - loss: 0.1324 - acc: 0.9400    \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 8s - loss: 0.1548 - acc: 0.9518     \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 12s - loss: 0.1283 - acc: 0.9581    \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 10s - loss: 0.1304 - acc: 0.9598    \n",
      " For row 0 : we get the average cross validation score of 0.976: model paras = [  0.03164254   0.1080271   10.          30.           3.        ] \n",
      " Getting in paras2d of shape = (1, 5)\n",
      " For row 0 , learning rate = 0.00436, num_layers = 10, hidden_units = 30, dropout_rate = 0.0780563225893, num_epoch = 2.0    \n",
      "Epoch 1/2\n",
      "35877/35877 [==============================] - 14s - loss: 0.2144 - acc: 0.9085    \n",
      "Epoch 2/2\n",
      "35877/35877 [==============================] - 10s - loss: 0.1346 - acc: 0.9412    \n",
      "Epoch 1/2\n",
      "35877/35877 [==============================] - 9s - loss: 0.1580 - acc: 0.9457     \n",
      "Epoch 2/2\n",
      "35877/35877 [==============================] - 10s - loss: 0.1148 - acc: 0.9647    \n",
      " For row 0 : we get the average cross validation score of 0.974: model paras = [  4.35642993e-03   7.80563226e-02   1.00000000e+01   3.00000000e+01\n",
      "   2.00000000e+00] \n",
      " Getting in paras2d of shape = (1, 5)\n",
      " For row 0 , learning rate = 0.03006, num_layers = 10, hidden_units = 30, dropout_rate = 0.115650308865, num_epoch = 3.0    \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 13s - loss: 0.1952 - acc: 0.9140    \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 10s - loss: 0.1465 - acc: 0.9314    \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 10s - loss: 0.1322 - acc: 0.9409    \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 11s - loss: 0.1797 - acc: 0.9381    \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 9s - loss: 0.1551 - acc: 0.9437     \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 10s - loss: 0.1414 - acc: 0.9508    \n",
      " For row 0 : we get the average cross validation score of 0.977: model paras = [  0.03005872   0.11565031  10.          30.           3.        ] \n",
      " Getting in paras2d of shape = (1, 5)\n",
      " For row 0 , learning rate = 0.02549, num_layers = 10, hidden_units = 30, dropout_rate = 0.132728249505, num_epoch = 3.0    \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 16s - loss: 0.2080 - acc: 0.9106    \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 17s - loss: 0.1581 - acc: 0.9285    \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 10s - loss: 0.1463 - acc: 0.9323    \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 11s - loss: 0.1725 - acc: 0.9418    \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 10s - loss: 0.1321 - acc: 0.9531    \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 11s - loss: 0.1211 - acc: 0.9624    \n",
      " For row 0 : we get the average cross validation score of 0.974: model paras = [  2.54865205e-02   1.32728250e-01   1.00000000e+01   3.00000000e+01\n",
      "   3.00000000e+00] \n",
      " Getting in paras2d of shape = (1, 5)\n",
      " For row 0 , learning rate = 0.03188, num_layers = 10, hidden_units = 30, dropout_rate = 0.11399417114, num_epoch = 3.0    \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 14s - loss: 0.1896 - acc: 0.9157    \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 11s - loss: 0.1549 - acc: 0.9286    \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 9s - loss: 0.1409 - acc: 0.9359     \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 10s - loss: 0.1765 - acc: 0.9386    \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 9s - loss: 0.1572 - acc: 0.9450     \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 10s - loss: 0.1335 - acc: 0.9543    \n",
      " For row 0 : we get the average cross validation score of 0.975: model paras = [  0.03188386   0.11399417  10.          30.           3.        ] \n",
      " Getting in paras2d of shape = (1, 5)\n",
      " For row 0 , learning rate = 0.03369, num_layers = 10, hidden_units = 30, dropout_rate = 0.10381666324, num_epoch = 3.0    \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 15s - loss: 0.2139 - acc: 0.9070    \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 11s - loss: 0.1595 - acc: 0.9284    \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 11s - loss: 0.1443 - acc: 0.9355    \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 9s - loss: 0.1679 - acc: 0.9465     \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 10s - loss: 0.1284 - acc: 0.9574    \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 9s - loss: 0.1342 - acc: 0.9586     \n",
      " For row 0 : we get the average cross validation score of 0.962: model paras = [  0.03368605   0.10381666  10.          30.           3.        ] \n",
      " Getting in paras2d of shape = (1, 5)\n",
      " For row 0 , learning rate = 0.05839, num_layers = 10, hidden_units = 30, dropout_rate = 0.136909118868, num_epoch = 3.0    \n",
      "Epoch 1/3\n",
      "35877/35877 [==============================] - 16s - loss: 0.2408 - acc: 0.8989    \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 11s - loss: 0.1837 - acc: 0.9145    \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 11s - loss: 0.1618 - acc: 0.9263    \n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35877/35877 [==============================] - 10s - loss: 0.3422 - acc: 0.9038    \n",
      "Epoch 2/3\n",
      "35877/35877 [==============================] - 11s - loss: 0.1770 - acc: 0.9393    \n",
      "Epoch 3/3\n",
      "35877/35877 [==============================] - 10s - loss: 0.1581 - acc: 0.9462    \n",
      " For row 0 : we get the average cross validation score of 0.974: model paras = [  0.05838656   0.13690912  10.          30.           3.        ] \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmIAAAFRCAYAAADXUMF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/1f44vnfYi0UAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe33b0b8cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "opt.run_optimization(max_iter=10)\n",
    "opt.plot_convergence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtained parameters during the search process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameter was"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.03005872,   0.11565031,  10.        ,  30.        ,   3.        ])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.x_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best cost was (1 - AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02349265])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.fx_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the parameters on model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtained the searched parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " For row 0 , learning rate = 0.03006, num_layers = 10, hidden_units = 30, dropout_rate = 0.115650308865, num_epoch = 3.0    \n"
     ]
    }
   ],
   "source": [
    "model = get_model_from_paras_row(opt.x_opt, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epoch = int(opt.x_opt[4])\n",
    "num_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trained the model for the whole training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "71754/71754 [==============================] - 23s - loss: 0.2647 - acc: 0.9065    \n",
      "Epoch 2/3\n",
      "71754/71754 [==============================] - 20s - loss: 0.2188 - acc: 0.9291    \n",
      "Epoch 3/3\n",
      "71754/71754 [==============================] - 20s - loss: 0.2055 - acc: 0.9371    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe30d8542e8>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train.values, Y_train_encoded, \n",
    "                      epochs=num_epoch, batch_size=batch_size, shuffle=True,\n",
    "                      callbacks = None, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Test on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96351720705393928"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results(model, X_test.values, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
